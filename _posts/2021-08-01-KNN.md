---
layout: splash
title: "K-Nearest Neighbor"
categories: R
tag: coding
---
# KNN(K-Nearest Neighbor)
<img src="\assets\images\KNN\Diagram.png" alt="Alt text">
Image Source : towardsdatascience
<br/>
 - Calculates the distance between an unidentified data point and closest identified data points
 - if k = 3, the model calculates the 3 nearest data points and the unidentified point is classified as the majority class of the 3 nearest points
 - Lazy model : No separate training is required. saving the training dataset is the only step required.
 - Euclidean distance is most commonly used.

#### Strenghts
 - High accuracy
 - No assumptions about the dataset are necessary
 - Outliers do not greatly influence the model

#### Weaknesses
 - Slow / Large use of memory
 - Larger the data dimensions, the slower the model
 - The more dimensions, the more data points that are necessary

<pre>
Code Example : 

library(class)
library(kknn)
library(e1071)
library(kernlab)
library(caret)
library(MASS)
library(reshape2)
library(ggplot2)
library(pROC)

    Import Data : 
        data(Pima.tr)
        data(Pima.te)
        pima <- rbind(Pima.tr, Pima.te)

        pima.melt <- melt(pima,id.var = "type") 
        
    Plot data : 
        ggplot(data = pima.melt, aes(x=type, y=value))+geom_boxplot()+facet_wrap(~variable, ncol=2)

    Scale Data : 
        pima.scale <- data.frame(scale(pima[,-8]))   
        pima.scale$type <- pima$type

        pima.scale.melt <- melt(pima.scale, id.var = "type")
        ggplot(data = pima.scale.melt, aes(x=type, y=value))
        +geom_boxplot()
        +facet_wrap(~variable, ncol=2)


    Split training set, test set : 
        set.seed(502)
        ind <- sample(2,nrow(pima.scale), 
                    replace = TRUE, 
                    prob = c(0.7,0.3))

        train <- pima.scale[ind==1,]
        test <- pima.scale[ind==2,]
    
    Create model with optimized parameters
        grid1 <- expand.grid(.k = seq(2,20,1))
        library(caret)
        control <- trainControl(method = "cv")

        set.seed(502)
        knn.train <- train(type ~.,
                        data = train,
                        method = "knn",
                        trControl=control,
                        tuneGrid = grid1)

        knn.test <- class::knn(train[, -8], test[, -8], train[, 8], k = 17)

    Evaluate model : 
        table(knn.test, test$type)
        (77+28)/147

        #calculate Kappa
        prob.agree <- (77+28)/147                        #Accuracy
        prob.chance <- ((77+26)/147) * ((77+16)/147)     #The probability you will get it right even by chance
        prob.chance
        kappa <- (prob.agree - prob.chance) / (1 - prob.chance)
        kappa

</pre>